{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MALIS-Project-v0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurilaatu/malis/blob/PreProcessing/MALIS_Project_v0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdhRsWKvz6Z",
        "colab_type": "text"
      },
      "source": [
        "## MALIS 2019 EURECOM\n",
        "## Course Project\n",
        "\n",
        "This is version zero of our semester project. We will load and prepare the data. Train a CNN to to extract features and use an ANN or SVM to classify the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAwvC2F8zxf3",
        "colab_type": "text"
      },
      "source": [
        "### Description\n",
        "\n",
        "**Task 1**: **bold text** Project definition for Group 34\n",
        "\tBy:\n",
        "Lauri Laatu\n",
        "Marvin Mouroum\n",
        "\n",
        "\n",
        "**•Context & problem definition**\n",
        "\n",
        "Classifying images is a huge topic in machine learning. The goal for our project is to be able to classify images to multiple classes. More specifically we want to investigate if a simple convolutional neural network is able to classify internet memes correctly. As such our it is a supervised learning problem.\n",
        "\n",
        "\n",
        "**•Methodology**\n",
        "\n",
        "Convolution for feature extraction\n",
        "RGB images will be fetched from a database\n",
        "preprocessing to optimize image dimensions\n",
        "convolution over three color channels of the images\n",
        "exporting a feature vector containing compressed information about the image\n",
        "ANN or SVM for classification based on extracted features\n",
        "feature vectors as labeled input\n",
        "supervised multiclass classification problem\n",
        "dataset usage: initially we plan to start with n-fold cross validation and 10% testing\n",
        "classification in predefined meme categories\n",
        "\n",
        "\n",
        "**•Data**\n",
        "\n",
        "The data will be acquired from the internet and labeled by hand if the data is unlabelled. Goal is to find around a thousand images per class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ao_F4lHwV9D",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "Loading data from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb9dl9KLvstO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import drive as gdrive\n",
        "from pydrive.auth import GoogleAuth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7KVtVoVkFzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DDm52EYwwq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#gdrive.mount('/content/gdrive')\n",
        "#root_path = 'gdrive/My Drive/DeepLearning/VideoBatches/subject01/'\n",
        "file_ids = []\n",
        "\n",
        "#file_id  => the id used to share file in the drive\n",
        "#img_name => the new local filename of the file \n",
        "def load_file(file_id, img_name):\n",
        "  \n",
        "  print(\"loading file:\\n\",file_id)\n",
        "  \n",
        "  drive = GoogleDrive(gauth)\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(img_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRGH3JPXxbwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing the method\n",
        "import cv2\n",
        "\n",
        "load_file(\"10DpgRQAxqIU0TLYCruSGPaj3DfRzh6TE\",\"folder_path\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFYxrppMi9Rr",
        "colab_type": "code",
        "outputId": "75891fe6-e22a-4101-c734-3830d3a92958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  gdrive  image_path  image_path.png  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfjx4Dfelug8",
        "colab_type": "code",
        "outputId": "49e28cb5-2360-4b91-a248-7ec02595ca35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "!pwd\n",
        "!ls\n",
        "\n",
        "gdrive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive/MALIS_Project/DataSet/rare-pepes\" |tail -n 10\n",
        "from IPython.display import Image\n",
        "display(Image('/content/drive/My Drive/MALIS_Project/DataSet/rare-pepes/001 - OdrldTF.png'))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "adc.json  sample_data\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "ultra-rare frog hand pic $$limited$$.png\n",
            "vwGz1Dq.jpg\n",
            "Welp+since+i+cant+reply+to+your+newest+message+i+ll+_1984bcbb4f9e6be9616e15a24dabea11.jpg\n",
            "XwrWv1Y.gif\n",
            "Yeah+and+the+ones+i+do+have+are+not+female+_20e4fbcdaebe3ca741ab5de8a318bc42.jpg\n",
            "Yeah+k+i+ll+try+contactin+you+in+2016+or+something+_aac28cdd447f1178e198b2149efeaec3.jpg\n",
            "yXXON1u.jpg\n",
            "zg5iAND.jpg\n",
            "zI1rqd1.png\n",
            "zkNDHin.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-97be7b321bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls \"/content/drive/My Drive/MALIS_Project/DataSet/rare-pepes\" |tail -n 10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/MALIS_Project/DataSet/rare-pepes/001 - OdrldTF.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ztr9ThQpGsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir  dataset\n",
        "\n",
        "file_list = drive.ListFile({'q': \"'10DpgRQAxqIU0TLYCruSGPaj3DfRzh6TE' in parents and trashed=false\"}).GetList()\n",
        "\n",
        "root = \"/content/drive/My Drive/MALIS_Project/DataSet/rare-pepes/\"\n",
        "i = 0\n",
        "\n",
        "#!cp \"/content/drive/My Drive/MALIS_Project/DataSet/rare-pepes/001 - OdrldTF.png\" \"dataset/pepe_00.png\"\n",
        "\n",
        "for file in file_list:\n",
        "  target = \"'dataset/pepe_\"+str(i)+\".png'\"\n",
        "  src    = \"'\"+root+file['title']+\"'\"\n",
        "  #print(src)\n",
        "  #print(target)\n",
        "  !cp $src $target\n",
        "  i+=1\n",
        "\n",
        "!ls -1 dataset\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGha5m-FkgJw",
        "colab_type": "code",
        "outputId": "e01c0830-b896-407c-c821-602e51d0d230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from IPython.display import Image\n",
        "display(Image('image_path.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "image_path.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGp94evi40y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img,destination):\n",
        "  # Create square images from pepes by adding black margins preserving original aspect ratio\n",
        "  #Importing modules opencv + numpy\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "\n",
        "  #Reading an image (you can use PNG or JPG)\n",
        "  img = cv2.imread(img)\n",
        "\n",
        "  if img is None:\n",
        "    return False\n",
        "\n",
        "  #Getting the bigger side of the image\n",
        "  s = max(img.shape[0:2])\n",
        "\n",
        "  #Creating a dark square with NUMPY  \n",
        "  f = np.zeros((s,s,3),np.uint8)\n",
        "\n",
        "  #Getting the centering position\n",
        "  ax,ay = (s - img.shape[1])//2,(s - img.shape[0])//2\n",
        "\n",
        "  #Pasting the 'image' in a centering position\n",
        "  f[ay:img.shape[0]+ay,ax:ax+img.shape[1]] = img\n",
        "\n",
        "  #Showing results (just in case) \n",
        "  #cv2.imshow(\"IMG\",f)\n",
        "  #A pause, waiting for any press in keyboard\n",
        "  #cv2.waitKey(0)\n",
        "\n",
        "  #Saving the image\n",
        "  f = cv2.resize(f,(256,256),interpolation=cv2.INTER_AREA)\n",
        "  cv2.imwrite(destination,f)\n",
        "  cv2.destroyAllWindows() \n",
        "  return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exGit1f3klTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "54bc606e-78d6-483b-9b37-3ce1b1b3c2b3"
      },
      "source": [
        "!mkdir resized\n",
        "for i in range(0,1273):\n",
        "  path =   \"dataset/pepe_\" + str(i) + \".png\"\n",
        "  _path = \"'resized/pepe_\" + str(i) + \".png'\"\n",
        "  prev_dest = \"resized/pepe_\" + str(i) + \".png\"\n",
        "  destination = \"'/content/drive/My Drive/MALIS_Project/DataSet/resized_pepe/pepe_\" + str(i) + \".png'\"\n",
        "  if not resize_img(path,prev_dest):\n",
        "    print(\"error with\", i)\n",
        "  !cp $_path $destination \n",
        "  if(i%50 == 0):\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘resized’: File exists\n",
            "0\n",
            "50\n",
            "error with 64\n",
            "cp: cannot stat 'resized/pepe_64.png': No such file or directory\n",
            "100\n",
            "150\n",
            "200\n",
            "error with 201\n",
            "cp: cannot stat 'resized/pepe_201.png': No such file or directory\n",
            "error with 236\n",
            "cp: cannot stat 'resized/pepe_236.png': No such file or directory\n",
            "250\n",
            "300\n",
            "error with 319\n",
            "cp: cannot stat 'resized/pepe_319.png': No such file or directory\n",
            "error with 321\n",
            "cp: cannot stat 'resized/pepe_321.png': No such file or directory\n",
            "error with 331\n",
            "cp: cannot stat 'resized/pepe_331.png': No such file or directory\n",
            "350\n",
            "400\n",
            "error with 421\n",
            "cp: cannot stat 'resized/pepe_421.png': No such file or directory\n",
            "error with 442\n",
            "cp: cannot stat 'resized/pepe_442.png': No such file or directory\n",
            "450\n",
            "error with 466\n",
            "cp: cannot stat 'resized/pepe_466.png': No such file or directory\n",
            "error with 482\n",
            "cp: cannot stat 'resized/pepe_482.png': No such file or directory\n",
            "500\n",
            "550\n",
            "error with 576\n",
            "cp: cannot stat 'resized/pepe_576.png': No such file or directory\n",
            "600\n",
            "error with 641\n",
            "cp: cannot stat 'resized/pepe_641.png': No such file or directory\n",
            "650\n",
            "error with 662\n",
            "cp: cannot stat 'resized/pepe_662.png': No such file or directory\n",
            "error with 671\n",
            "cp: cannot stat 'resized/pepe_671.png': No such file or directory\n",
            "700\n",
            "750\n",
            "error with 781\n",
            "cp: cannot stat 'resized/pepe_781.png': No such file or directory\n",
            "800\n",
            "error with 813\n",
            "cp: cannot stat 'resized/pepe_813.png': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBz62dkL_RkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}